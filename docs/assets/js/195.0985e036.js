(window.webpackJsonp=window.webpackJsonp||[]).push([[195],{524:function(t,n,e){"use strict";e.r(n);var s=e(12),r=Object(s.a)({},(function(){var t=this,n=t._self._c;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h2",{attrs:{id:"_1-命令简介"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-命令简介"}},[t._v("#")]),t._v(" 1.命令简介")]),t._v(" "),n("p",[t._v("wget 是一个非交互式网络下载器，用于从指定 url 下载文件。")]),t._v(" "),n("p",[t._v("wget 是 Linux 环境下流行的强大稳定的文件下载工具，主要有如下几个特点：")]),t._v(" "),n("ul",[n("li",[t._v("wget 支持的协议丰富，支持 HTTP、HTTPS 和 FTP 协议，可以使用 HTTP 代理；")]),t._v(" "),n("li",[t._v("wget 支持自动下载。wget 是非交互式的，这意味着它可以在后台工作。这意味这你可以登录系统，启动一个 wget 下载任务，然后退出系统，wget 将在后台执行直到任务完成；")]),t._v(" "),n("li",[t._v("wget 支持断点续传，即在下次下载文件时，从已经下载的部分开始继续下载未完成的部分，而没有必要从头开始下载；")]),t._v(" "),n("li",[t._v("wget 对弱网络有很强的适应性，在带宽很窄的情况下和不稳定网络中，如果由于网络的原因下载失败，wget 会不断地尝试，直到整个文件下载完毕。")])]),t._v(" "),n("h2",{attrs:{id:"_2-命令格式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-命令格式"}},[t._v("#")]),t._v(" 2.命令格式")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("wget [OPTION]... [URL]...\n")])])]),n("h2",{attrs:{id:"_3-选项说明"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-选项说明"}},[t._v("#")]),t._v(" 3.选项说明")]),t._v(" "),n("p",[t._v("注意，长选项所必须的参数在使用短选项时也是必须的。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("基本启动选项\n-V,  --version\n\t显示 wget 的版本信息并退出\n-h, --help\n\t打印帮助\n-b, --background\n\t启动后转入后台执行。如果没有通过 -o 指定输出文件，则将输出重定向到 wget-log\n-e,  --execute=COMMAND\n\t执行命令，就好像命令是 .wgetrc 的一部分一样。命令将在 .wgetrc 中的命令之后执行。如果需要指定多个 .wgetrc 命令，请使用 -e 的多个实例\n\n日志和输入文件选项\n-o,  --output-file=LOGFILE\n  \t将日志信息写入 LOGFILE\n-a,  --append-output=LOGFILE\n\t将日志信息追加至 LOGFILE，而不是覆盖原 LOGFILE\n-d, --debug\n\t打印大量调试信息\n-q, --quiet\n\t安静模式（无信息输出）\n-v,  --verbose\n\t详尽的输出（此为默认设置）\n-nv, --no-verbose\n\t关闭详尽输出，但不进入安静模式。这意味着错误信息和基本信息仍然会被打印出来\n-i, --input-file=FILE\n\t下载本地或外部 FILE 中的 URLs\n-F, --force-html\n\t把输入文件当成 HTML 文件\n-B, --base=URL\n\t将 URL 作为在 -F -i 参数指定的文件中出现的相对链接的前缀\n\n下载选项\n--bind-address=ADDRESS\n\t绑定至本地主机上的 ADDRESS (主机名或是 IP)\n-t,  --tries=NUMBER\n\t设置重试次数为 NUMBER (0 代表无限制)\n-O,  --output-document=FILE\n\t将下载的文档写入 FILE\n-nc, --no-clobber\n\t在同一个目录中下载同一个文件将导致文件的原始副本被保留，第二个副本被命名为 file.1，第三个为 file.2，以此类推\n-c,  --continue \n\t断点续传下载文件\n--progress=TYPE\n\t选择进度条类型，可取值 dot 和 bar\n-N,  --timestamping\n\t只获取比本地文件新的文件\n--no-use-server-timestamps\n  \t不用服务器上的时间戳来设置本地文件\n-S, --server-response\n  打印服务器响应\n--spider\n\t不下载任何文件，只检查文件是不是在那里\n-T,  --timeout=SECONDS\n  \t将所有超时设为 SECONDS 秒\n--dns-timeout=SECS\n\t设置 DNS 查寻超时为 SECS 秒\n--connect-timeout=SECS\n\t设置连接超时为 SECS 秒\n--read-timeout=SECS\n\t设置读取超时为 SECS 秒\n-w, --wait=SECONDS\n\t等待间隔为 SECONDS 秒\n--waitretry=SECONDS\n\t在获取文件的重试期间等待 SECONDS 秒\n--random-wait\n\t获取多个文件时，每次随机等待间隔在 0.5*WAIT 至 1.5*WAIT 秒，WAIT 由 -w 选项指定\n--no-proxy\n\t禁止使用代理\n-Q, --quota=NUMBER\n\t设置获取配额为 NUMBER 字节，后缀为 k（千字节）或 m（兆字节）。当下载的文件总大小达到配额后将暂停下载。请注意，配额不会影响下载单个文件。将配额设置为 0 或 inf 不限制下载配额\n--limit-rate=RATE\n\t限制下载速率为 RATE 字节每秒。RATE 可使用后缀 k（千字节）或 m（兆字节）\n--no-dns-cache\n\t关闭 DNS 查寻缓存\n--restrict-file-names=MODES\n\t限定文件名中的字符为 MODES 允许的字符\n-4,  --inet4-only\n  \t仅连接至 IPv4 地址\n-6,  --inet6-only\n\t仅连接至 IPv6 地址\n--prefer-family=FAMILY\n\t首先连接至指定协议的地址。FAMILY 为 IPv6，IPv4 或是 none\n--retry-connrefused\n\t即使拒绝连接也要重试\n--user=USER\n\t将 ftp 和 http 的用户名均设置为 USER\n--password=PASS\n\t将 ftp 和 http 的密码均设置为 PASS\n--ask-password\n\t提示输入密码\n--no-iri\n\t关闭国际化 URI(IRI) 的支持\n--local-encoding=ENC\n\tIRI (国际化资源标识符) 使用 ENC 作为本地编码\n--remote-encoding=ENC\n\t使用 ENC 作为默认远程编码\n\n目录选项\n-nd, --no-directories\n\t不创建目录\n-x,  --force-directories\n\t强制创建目录\n-nH, --no-host-directories\n\t不要创建主目录\n--protocol-directories\n\t在目录中使用协议名称\n-P,  --directory-prefix=PREFIX\n\t以 PREFIX/ 作为前缀来保存文件\n--cut-dirs=NUMBER\n\t忽略远程目录中 NUMBER 个目录层\n\nHTTP 选项\n--http-user=USER\n\t设置 http 用户名为 USER\n--http-password=PASS\n\t设置 http 密码为 PASS\n--no-cache\n\t不在服务器上缓存数据\n--default-page=NAME\n\t改变默认页 (默认页通常是 index.html)\n  -E,  --adjust-extension\n  \t以合适的扩展名保存 HTML/CSS 文档\n--ignore-length\n\t忽略头部的 Content-Length 区域\n--header=STRING\n\t在头部插入 STRING\n--max-redirect\n\t每页所允许的最大重定向\n--proxy-user=USER\n\t使用 USER 作为代理用户名\n--proxy-password=PASS\n\t使用 PASS 作为代理密码\n--referer=URL\n\t在 HTTP 请求头包含 Referer:URL\n--save-headers\n\t将 HTTP 头保存至文件\n-U, --user-agent=AGENT\n\t标识为 AGENT 而不是 Wget/VERSION\n--no-http-keep-alive\n\t禁用 HTTP keep-alive (永久连接)\n--no-cookies\n\t不使用 cookies\n--load-cookies=FILE\n\t会话开始前从 FILE 中载入 cookies\n--save-cookies=FILE\n\t会话结束后保存 cookies 至 FILE\n--keep-session-cookies\n\t载入并保存会话 (非永久) cookies\n--post-data=STRING\n\t使用 POST 方式；把 STRING 作为数据发送\n--post-file=FILE\n\t使用 POST 方式；发送 FILE 内容\n--content-disposition\n\t当选中本地文件名时允许 Content-Disposition 头部 (尚在实验)\n--auth-no-challenge\n\t发送不含服务器询问的首次等待的基本 HTTP 验证信息\n\nHTTPS (SSL/TLS) 选项\n--secure-protocol=PR     选择安全协议，可以是 auto、SSLv2、SSLv3 或是 TLSv1 中的一个\n--no-check-certificate\n\t不要验证服务器的证书\n--certificate=FILE\n\t客户端证书文件\n--certificate-type=TYPE\n\t客户端证书类型，PEM 或 DER\n--private-key=FILE\n       私钥文件\n--private-key-type=TYPE\n\t私钥文件类型，PEM（默认） 或 DER\n--ca-certificate=FILE\n\t带有一组 CA 认证的文件\n--ca-directory=DIR\n\t保存 CA 认证的哈希列表的目录\n--random-file=FILE\n\t带有生成 SSL PRNG 的随机数据的文件\n--egd-file=FILE\n\t用于命名带有随机数据的 EGD 套接字的文件\n\nFTP 选项\n--ftp-user=USER\n\t设置 ftp 用户名为 USER\n--ftp-password=PASS\n\t设置 ftp 密码为 PASS\n--no-remove-listing\n\t不要删除 FTP 检索生成的临时 .list 文件\n --no-glob\n \t不在 FTP 文件名中使用通配符展开\n--no-passive-ftp\n\t禁用 passive 传输模式\n--retr-symlinks\n\t递归目录时，获取符号链接指向的文件\n\n递归下载选项\n-r,  --recursive\n\t指定递归下载\n-l,  --level=NUMBER\n\t最大递归深度 (inf 或 0 代表无限制，即全部下载)\n--delete-after\n\t下载完成后删除本地文件\n-k,  --convert-links\n\t让下载得到的 HTML 或 CSS 中的链接指向本地文件\n-K,  --backup-converted\n\t在转换文件 X 前先将它备份为 X.orig\n-m, --mirror\n\t打开适合镜像的选项。此选项打开递归和时间戳，设置无限递归深度，并保留ftp目录列表。等价于 -N -r -l inf --no-remove-listing 选项\n-p,  --page-requisites\n\t下载所有用于显示 HTML 页面的图片之类的元素\n--strict-comments\n\t用严格方式 (SGML) 处理 HTML 注释\n\n递归接受/拒绝选项\n-A,  --accept=LIST\n\t逗号分隔的可接受的扩展名列表\n-R,  --reject=LIST\n\t逗号分隔的要拒绝的扩展名列表\n-D,  --domains=LIST\n\t逗号分隔的可接受的域列表\n--exclude-domains=LIST\n\t逗号分隔的要拒绝的域列表\n--follow-ftp\n\t跟踪 HTML 文档中的 FTP 链接\n--follow-tags=LIST\n\t逗号分隔的跟踪的 HTML 标识列表\n--ignore-tags=LIST\n\t逗号分隔的忽略的 HTML 标识列表\n-H,  --span-hosts\n\t递归时转向外部主机\n-L,  --relative\n\t只跟踪有关系的链接\n-I,  --include-directories=LIST\n\t允许目录的列表\n--trust-server-names\n\t在重定向时，重定向 URL 的最后一个组件将用作本地文件名。默认情况下，它是原始 URL 中的最后一个组件\n-X,  --exclude-directories=LIST\n\t排除目录的列表\n-np, --no-parent\n\t不追溯至父目录\n--ignore-case\n\t匹配文件/目录时忽略大小写\n")])])]),n("h2",{attrs:{id:"_4-常用示例"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-常用示例"}},[t._v("#")]),t._v(" 4.常用示例")]),t._v(" "),n("p",[t._v("（1）使用 wget 下载单个文件。")]),t._v(" "),n("p",[t._v("比如下载 git 的 Windows 客户端 "),n("a",{attrs:{href:"https://gitforwindows.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("git for windows"),n("OutboundLink")],1),t._v("。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("wget https://github.com/git-for-windows/git/releases/download/v2.25.1.windows.1/Git-2.25.1-32-bit.tar.bz2\n")])])]),n("p",[t._v("wget 虽然有很多选项，但是最常用的是不带任何选项，给定文件的 url 进行下载。")]),t._v(" "),n("p",[t._v("（2）下载单个文件，使用指定的文件名保存。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("wget -O GitForWindows.tar.bz2 https://github.com/git-for-windows/git/releases/download/v2.25.1.windows.1/Git-2.25.1-32-bit.tar.bz2\n")])])]),n("p",[t._v("（3）使用 wget  -b 将 wget 放在后台执行。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("wget -b https://github.com/git-for-windows/git/releases/download/v2.25.1.windows.1/Git-2.25.1-32-bit.tar.bz2\nContinuing in background, pid 9369.\nOutput will be written to 'wget-log'.\n")])])]),n("p",[t._v("对于下载非常大的文件的时候，我们可以使用参数 -b 进行后台下载，可以使用命令"),n("code",[t._v("tail -f wget-log")]),t._v("查看 wget 的日志文件 wget-log 来察看下载进度。")]),t._v(" "),n("p",[t._v("（4）使用 wget -c 断点续传。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("wget -c https://github.com/git-for-windows/git/releases/download/v2.25.1.windows.1/Git-2.25.1-32-bit.tar.bz2\n")])])]),n("p",[t._v("使用 wget -c 重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。")]),t._v(" "),n("p",[t._v("（5）使用 wget --spider 测试下载链接。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("wget --spider https://github.com/git-for-windows/git/releases/download/v2.25.1.windows.1/Git-2.25.1-32-bit.tar.bz2\n")])])]),n("p",[t._v("（6）现在多个文件。每个文件的下载链接统一存放在一个文件中。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("wget -i filelist.txt\n")])])]),n("p",[t._v("（7）使用 wget -o 将下载过程中的日志信息存入到日志文件，而不是输出到终端。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("wget -o wget.log https://github.com/git-for-windows/git/releases/download/v2.25.1.windows.1/Git-2.25.1-32-bit.tar.bz2\n")])])]),n("hr"),t._v(" "),n("h2",{attrs:{id:"参考文献"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#参考文献"}},[t._v("#")]),t._v(" 参考文献")]),t._v(" "),n("p",[n("a",{attrs:{href:"https://man7.org/linux/man-pages/man1/wget.1.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("wget(1) - Linux manual page - man7.org"),n("OutboundLink")],1)]),t._v(" "),n("p",[n("a",{attrs:{href:"https://blog.csdn.net/dengjin20104042056/article/details/100145281",target:"_blank",rel:"noopener noreferrer"}},[t._v("CSDN.【Linux】一步一步学Linux——wget命令(192)"),n("OutboundLink")],1)]),t._v(" "),n("p",[n("a",{attrs:{href:"https://www.gnu.org/software/wget/",target:"_blank",rel:"noopener noreferrer"}},[t._v("GNU wget 官网"),n("OutboundLink")],1)])])}),[],!1,null,null,null);n.default=r.exports}}]);